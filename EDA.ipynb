{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: phiusiil\n",
      "                                         url  label\n",
      "0                      https://www.gdc.co.ke      0\n",
      "1               https://www.astrotrishla.com      0\n",
      "2                      https://www.npstc.org      0\n",
      "3  https://www.harrisburgregionalchamber.org      0\n",
      "4                https://www.cincymuseum.org      0\n",
      "Processing dataset: malicious_phish\n",
      "                                                 url  label\n",
      "0  firedepartmentdirectory.com/location/County-Fi...      0\n",
      "1  sopfeu.qc.ca/en/etat_de_la_situation/danger_in...      0\n",
      "2               filecatch.com/?q=zuzana+rock+body+tv      0\n",
      "3  http://tobogo.net/cdsb/board.php?board=storyan...      0\n",
      "4   kindomain2.com/3a6a5a4bf24172a7bbf51eae887700ad/      0\n",
      "Processing dataset: url_dataset\n",
      "                                                 url  label\n",
      "0  https://www.countrydiscography.blogspot.com/20...      0\n",
      "1   https://www.en.wikipedia.org/wiki/Peter_Bronfman      0\n",
      "2  https://www.atlanticbassmasters.com/Lake%20Rec...      0\n",
      "3  https://www.pipl.com/directory/tags/Fraser%252...      0\n",
      "4  https://www.ca.linkedin.com/directory/people/c...      0\n",
      "Processing dataset: combined\n",
      "                                                 url  label\n",
      "0  www.shudokanaikido.i15.eu/sklep/language/pl-PL...      0\n",
      "1  https://www.io9.com/351419/whos-the-tallest-gi...      0\n",
      "2                         https://www.lundfloral.net      0\n",
      "3  itunes.apple.com/us/artist/jeffrey-steele/id18...      0\n",
      "4                          https://www.newsaero.info      0\n",
      "Plots saved in the EDA folder.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from urllib.parse import urlparse\n",
    "from utils.data_utils import *\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Create the EDA directory if it doesn't exist\n",
    "os.makedirs('EDA', exist_ok=True)\n",
    "\n",
    "# List of datasets to import\n",
    "datasets = [\"phiusiil\", \"malicious_phish\", \"url_dataset\", \"combined\"]\n",
    "\n",
    "# Loop through each dataset type\n",
    "for to_import in datasets:\n",
    "    # Import dataset\n",
    "    if to_import == \"phiusiil\":\n",
    "        train, validation, benchmark = import_phiusiil()\n",
    "    elif to_import == \"malicious_phish\":\n",
    "        train, validation, benchmark = import_malicious_phish()\n",
    "    elif to_import == \"url_dataset\":\n",
    "        train, validation, benchmark = import_url_dataset()\n",
    "    elif to_import == \"combined\":\n",
    "        train, validation, benchmark = import_combined(fraction=0.02)\n",
    "\n",
    "    # Load the dataset\n",
    "    df = train\n",
    "\n",
    "    # Display the first few rows of the dataset\n",
    "    print(f\"Processing dataset: {to_import}\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Feature Extraction Function\n",
    "    def extract_features(url):\n",
    "        parsed_url = urlparse(url)\n",
    "        domain = parsed_url.netloc\n",
    "        \n",
    "        # Calculate features\n",
    "        url_length = len(url)\n",
    "        domain_length = len(domain)\n",
    "        subdomain_count = domain.count('.') - 1  # Count dots to estimate subdomains\n",
    "        path_length = len(parsed_url.path)\n",
    "        query_param_count = len(parsed_url.query.split('&')) if parsed_url.query else 0\n",
    "        is_https = 1 if parsed_url.scheme == 'https' else 0\n",
    "        special_char_count = len(re.findall(r'[!@#$%^&*(),.?\":{}|<>]', url))\n",
    "        is_ip_address = 1 if re.match(r'^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$', domain) else 0\n",
    "        last_path_segment_length = len(parsed_url.path.split('/')[-1]) if parsed_url.path else 0\n",
    "        \n",
    "        # Check for suspicious keywords\n",
    "        suspicious_keywords = ['login', 'secure', 'update', 'account', 'verify']\n",
    "        contains_suspicious_keyword = any(keyword in url.lower() for keyword in suspicious_keywords)\n",
    "\n",
    "        return pd.Series([\n",
    "            url_length,\n",
    "            domain_length,\n",
    "            subdomain_count,\n",
    "            path_length,\n",
    "            query_param_count,\n",
    "            is_https,\n",
    "            special_char_count,\n",
    "            is_ip_address,\n",
    "            last_path_segment_length,\n",
    "            int(contains_suspicious_keyword)\n",
    "        ])\n",
    "\n",
    "    # Apply feature extraction to each URL\n",
    "    df[['url_length', 'domain_length', 'subdomain_count', 'path_length',\n",
    "        'query_param_count', 'is_https', 'special_char_count',\n",
    "        'is_ip_address', 'last_path_segment_length', 'contains_suspicious_keyword']] = df['url'].apply(extract_features)\n",
    "\n",
    "    # Create the EDA directory if it doesn't exist\n",
    "    os.makedirs('EDA', exist_ok=True)\n",
    "\n",
    "    # Create a subfolder for the specific dataset\n",
    "    dataset_folder = f'EDA/{to_import}'\n",
    "    os.makedirs(dataset_folder, exist_ok=True)\n",
    "\n",
    "    # Visualizing URL Length Distribution and saving the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['url_length'], bins=30, kde=True)\n",
    "    plt.title(f'Distribution of URL Lengths ({to_import})')\n",
    "    plt.xlabel('Length of URL')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{dataset_folder}/distribution_url_lengths_{to_import}.png')  # Save plot in specific dataset folder\n",
    "    plt.close()  # Close the plot to free memory\n",
    "\n",
    "    # Set limits for x-axis based on significance for each feature\n",
    "    x_limits = {\n",
    "        'last_path_segment_length': (0, 5),  # Adjust these limits based on your data analysis\n",
    "        'special_char_count': (0, 10),        # Adjust these limits based on your data analysis\n",
    "        'domain_length': (0, 30),             # Adjust these limits based on your data analysis\n",
    "        'path_length': (0, 50)                # Adjust these limits based on your data analysis\n",
    "    }\n",
    "\n",
    "    # Visualizing counts for new features and saving each plot with x-axis limits applied\n",
    "    feature_columns = ['domain_length', 'subdomain_count', 'path_length', \n",
    "                       'query_param_count', 'is_https', \n",
    "                       'special_char_count', 'is_ip_address',\n",
    "                       'last_path_segment_length', \n",
    "                       'contains_suspicious_keyword']\n",
    "\n",
    "    for feature in feature_columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        if feature in x_limits:\n",
    "            sns.countplot(x=feature, data=df)\n",
    "            plt.xlim(x_limits[feature])  # Set x-axis limits only for specified features\n",
    "        else:\n",
    "            sns.countplot(x=feature, data=df)\n",
    "\n",
    "        plt.title(f'Count of {feature} ({to_import})')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.savefig(f'{dataset_folder}/count_{feature}_{to_import}.png')  # Save plot in specific dataset folder\n",
    "        plt.close()  # Close the plot to free memory\n",
    "\n",
    "print(\"Plots saved in the EDA folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc4001-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
